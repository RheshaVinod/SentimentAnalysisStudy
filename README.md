**Comparative Study of Word Embedding Representations for Sentiment Classification**
This project compares different word embedding techniques and machine learning models for sentiment classification using Amazon product reviews.

**We evaluate:**

  Pretrained embeddings (word2vec-google-news-300)
  
  Domain-specific Word2Vec embeddings trained on Amazon reviews

**Across multiple models:**

  Perceptron
  
  SVM
  
  MLP (2 hidden layers: 50 → 10)
  
  CNN (2 Conv1D layers: 50 → 10 channels)
  
  Both binary (positive vs negative) and ternary (positive, negative, neutral) classification tasks are performed.
